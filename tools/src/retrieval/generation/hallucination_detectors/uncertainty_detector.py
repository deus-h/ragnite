"""
Uncertainty Detector

This module defines the UncertaintyDetector that identifies statements with hedging,
vague language, or uncertainty markers in language model outputs.
"""

import re
from typing import Any, Dict, List, Optional, Union, Set
from .base_hallucination_detector import BaseHallucinationDetector, HallucinationDetectionResult


class UncertaintyDetector(BaseHallucinationDetector):
    """
    Detector for identifying uncertain statements in generated text.
    
    This detector analyzes generated text to identify statements that contain
    hedging language, uncertainty markers, or vague expressions that may
    indicate a lack of confidence in the generated information.
    
    Attributes:
        uncertainty_markers (List[str]): List of phrases indicating uncertainty.
        hedging_phrases (List[str]): List of hedging phrases.
        speculative_phrases (List[str]): List of speculative phrases.
        probability_markers (List[str]): List of phrases indicating probability.
        threshold (float): Confidence threshold for considering a statement uncertain.
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the uncertainty detector.
        
        Args:
            config: Configuration dictionary that may include:
                - uncertainty_markers: List of phrases indicating uncertainty
                - hedging_phrases: List of hedging phrases
                - speculative_phrases: List of speculative phrases
                - probability_markers: List of phrases indicating probability
                - threshold: Confidence threshold (default: 0.5)
                - severity_weights: Weights for different uncertainty categories
        """
        super().__init__(config)
        self.uncertainty_markers = self.config.get("uncertainty_markers")
        self.hedging_phrases = self.config.get("hedging_phrases")
        self.speculative_phrases = self.config.get("speculative_phrases")
        self.probability_markers = self.config.get("probability_markers")
        self.threshold = self.config.get("threshold", 0.5)
        self.severity_weights = self.config.get("severity_weights", {
            "hedging": 0.7,
            "uncertainty": 0.8,
            "speculation": 0.6,
            "probability": 0.5
        })
        
        # Load default markers if not provided
        if not self.uncertainty_markers:
            self.uncertainty_markers = self._get_default_uncertainty_markers()
        
        if not self.hedging_phrases:
            self.hedging_phrases = self._get_default_hedging_phrases()
        
        if not self.speculative_phrases:
            self.speculative_phrases = self._get_default_speculative_phrases()
        
        if not self.probability_markers:
            self.probability_markers = self._get_default_probability_markers()
    
    def detect(self, 
               generated_text: str, 
               source_documents: Optional[List[Dict[str, Any]]] = None, 
               **kwargs) -> Dict[str, Any]:
        """
        Detect uncertain statements in the generated text.
        
        Args:
            generated_text: The text generated by the language model.
            source_documents: Optional list of source documents (not used for uncertainty detection).
            **kwargs: Additional arguments:
                - extract_claims: Whether to extract specific claims for uncertainty detection
                - ignore_markers: List of uncertainty markers to ignore
                
        Returns:
            A dictionary containing detection results.
        """
        # Extract statements from generated text
        extract_claims = kwargs.get("extract_claims", True)
        if extract_claims:
            statements = self._extract_statements(generated_text)
        else:
            # Use the entire text as a single statement
            statements = [{
                "statement": generated_text,
                "span": (0, len(generated_text))
            }]
        
        # Get markers to ignore
        ignore_markers = set(kwargs.get("ignore_markers", []))
        
        # Detect uncertainty in each statement
        uncertain_statements = []
        
        for statement_info in statements:
            statement = statement_info["statement"]
            
            # Check for uncertainty markers
            uncertainty_result = self._check_uncertainty(
                statement, 
                ignore_markers
            )
            
            if uncertainty_result["is_uncertain"]:
                # Found an uncertain statement
                uncertain_statements.append({
                    "text": statement,
                    "span": statement_info["span"],
                    "reason": uncertainty_result["reason"],
                    "uncertainty_score": uncertainty_result["score"],
                    "markers": uncertainty_result["markers"],
                    "severity": uncertainty_result["severity"],
                    "confidence": uncertainty_result["confidence"]
                })
        
        # Calculate the overall uncertainty score
        if not uncertain_statements:
            score = 1.0  # Perfect score (no uncertainty)
            confidence = 0.8
            explanation = "No uncertain statements detected in the generated text."
        else:
            # Calculate score based on number and severity of uncertain statements
            total_statements = len(statements)
            uncertain_count = len(uncertain_statements)
            
            # Base score is percentage of certain statements
            certainty_ratio = 1.0 - (uncertain_count / total_statements)
            
            # Adjust based on severity of uncertainties
            severity_adjustment = sum(
                self._get_severity_weight(s["severity"]) for s in uncertain_statements
            ) / uncertain_count
            
            # Final score is certainty ratio adjusted by severity
            score = certainty_ratio * (1.0 - (0.5 * severity_adjustment))
            
            # Ensure score is in [0, 1] range
            score = max(0.0, min(1.0, score))
            
            # Calculate confidence as average of individual uncertainties
            confidence = sum(s["confidence"] for s in uncertain_statements) / uncertain_count
            
            # Generate explanation
            explanation = self._generate_explanation(uncertain_statements)
        
        # Convert to hallucination format
        detected_hallucinations = [
            {
                "text": s["text"],
                "span": s["span"],
                "reason": s["reason"],
                "severity": s["severity"],
                "confidence": s["confidence"],
                "markers": s["markers"]
            }
            for s in uncertain_statements
        ]
        
        # Create result object
        result = HallucinationDetectionResult(
            score=score,
            detected_hallucinations=detected_hallucinations,
            explanation=explanation,
            confidence=confidence,
            detection_type=self.get_detection_type()
        )
        
        return result.to_dict()
    
    def get_detection_type(self) -> str:
        """
        Get the type of hallucination detection performed.
        
        Returns:
            The string "uncertainty"
        """
        return "uncertainty"
    
    def _extract_statements(self, text: str) -> List[Dict[str, Any]]:
        """
        Extract individual statements from the generated text for uncertainty detection.
        
        Args:
            text: The generated text to analyze
            
        Returns:
            List of dictionaries with statement text and character spans
        """
        statements = []
        
        # Simple sentence splitting using regex
        # In a production system, use a more robust sentence tokenizer
        sentence_pattern = r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|\!)\s'
        spans = list(re.finditer(sentence_pattern, text))
        
        start_idx = 0
        for span in spans:
            end_idx = span.start() + 1  # Include the punctuation
            sentence = text[start_idx:end_idx].strip()
            
            if sentence:
                statements.append({
                    "statement": sentence,
                    "span": (start_idx, end_idx)
                })
            
            start_idx = span.end()
        
        # Don't forget the last sentence if it doesn't end with punctuation
        if start_idx < len(text):
            sentence = text[start_idx:].strip()
            if sentence:
                statements.append({
                    "statement": sentence,
                    "span": (start_idx, len(text))
                })
        
        return statements
    
    def _check_uncertainty(self, 
                         statement: str, 
                         ignore_markers: Set[str]) -> Dict[str, Any]:
        """
        Check for uncertainty markers in a statement.
        
        Args:
            statement: The statement to check
            ignore_markers: Set of markers to ignore
            
        Returns:
            Dictionary with uncertainty detection results
        """
        statement_lower = statement.lower()
        found_markers = {
            "hedging": [],
            "uncertainty": [],
            "speculation": [],
            "probability": []
        }
        
        # Check for hedging phrases
        for phrase in self.hedging_phrases:
            if phrase.lower() in statement_lower and phrase.lower() not in ignore_markers:
                found_markers["hedging"].append(phrase)
        
        # Check for uncertainty markers
        for marker in self.uncertainty_markers:
            if marker.lower() in statement_lower and marker.lower() not in ignore_markers:
                found_markers["uncertainty"].append(marker)
        
        # Check for speculative phrases
        for phrase in self.speculative_phrases:
            if phrase.lower() in statement_lower and phrase.lower() not in ignore_markers:
                found_markers["speculation"].append(phrase)
        
        # Check for probability markers
        for marker in self.probability_markers:
            if marker.lower() in statement_lower and marker.lower() not in ignore_markers:
                found_markers["probability"].append(marker)
        
        # Calculate total markers
        total_markers = sum(len(markers) for markers in found_markers.values())
        
        # If no markers found, statement is not uncertain
        if total_markers == 0:
            return {
                "is_uncertain": False,
                "score": 0.0,
                "reason": "No uncertainty markers detected",
                "markers": [],
                "severity": "none",
                "confidence": 0.8
            }
        
        # Calculate uncertainty score based on number and types of markers
        hedging_score = len(found_markers["hedging"]) * self.severity_weights["hedging"]
        uncertainty_score = len(found_markers["uncertainty"]) * self.severity_weights["uncertainty"]
        speculation_score = len(found_markers["speculation"]) * self.severity_weights["speculation"]
        probability_score = len(found_markers["probability"]) * self.severity_weights["probability"]
        
        # Weighted sum of scores
        total_score = (hedging_score + uncertainty_score + speculation_score + probability_score) / 4.0
        
        # Normalize score to [0, 1] range
        normalized_score = min(1.0, total_score)
        
        # Determine if the statement is uncertain based on threshold
        is_uncertain = normalized_score >= self.threshold
        
        if not is_uncertain:
            return {
                "is_uncertain": False,
                "score": normalized_score,
                "reason": "Uncertainty score below threshold",
                "markers": [],
                "severity": "none",
                "confidence": 0.7
            }
        
        # Determine severity
        if normalized_score >= 0.8:
            severity = "high"
            confidence = 0.9
        elif normalized_score >= 0.6:
            severity = "medium"
            confidence = 0.8
        else:
            severity = "low"
            confidence = 0.7
        
        # Flatten markers for easier display
        all_markers = []
        for category, markers in found_markers.items():
            all_markers.extend(markers)
        
        # Generate reason
        if found_markers["uncertainty"]:
            primary_category = "uncertainty"
        elif found_markers["hedging"]:
            primary_category = "hedging"
        elif found_markers["speculation"]:
            primary_category = "speculation"
        else:
            primary_category = "probability"
        
        reason = f"Contains {primary_category} markers: {', '.join(found_markers[primary_category][:3])}"
        if len(found_markers[primary_category]) > 3:
            reason += f" and {len(found_markers[primary_category]) - 3} more"
        
        return {
            "is_uncertain": True,
            "score": normalized_score,
            "reason": reason,
            "markers": all_markers,
            "severity": severity,
            "confidence": confidence
        }
    
    def _get_severity_weight(self, severity: str) -> float:
        """
        Get weight for a severity level.
        
        Args:
            severity: Severity level ("low", "medium", "high")
            
        Returns:
            Severity weight
        """
        weights = {
            "low": 0.3,
            "medium": 0.6,
            "high": 0.9,
            "none": 0.0
        }
        
        return weights.get(severity, 0.0)
    
    def _get_default_uncertainty_markers(self) -> List[str]:
        """
        Get default uncertainty markers.
        
        Returns:
            List of uncertainty markers
        """
        return [
            "uncertain", "unclear", "unknown", "not clear", "not certain",
            "not sure", "not known", "ambiguous", "vague", "unsure",
            "doubt", "doubtful", "questionable", "debatable", "disputed",
            "controversial", "undetermined", "unverified"
        ]
    
    def _get_default_hedging_phrases(self) -> List[str]:
        """
        Get default hedging phrases.
        
        Returns:
            List of hedging phrases
        """
        return [
            "seems to be", "appears to be", "might be", "could be", "may be",
            "possibly", "potentially", "perhaps", "probably", "likely",
            "unlikely", "supposedly", "allegedly", "reportedly", "apparently",
            "it is possible that", "it is likely that", "it seems that",
            "it appears that", "to some extent", "to a certain degree",
            "kind of", "sort of", "somewhat", "rather", "quite", "fairly"
        ]
    
    def _get_default_speculative_phrases(self) -> List[str]:
        """
        Get default speculative phrases.
        
        Returns:
            List of speculative phrases
        """
        return [
            "I think", "I believe", "I assume", "I suspect", "I suppose",
            "I guess", "I would say", "it is thought that", "it is believed that",
            "it is speculated that", "it is assumed that", "theory suggests",
            "researchers speculate", "scientists believe", "experts think",
            "there is speculation that", "there is a theory that",
            "speculate", "theorize", "hypothesize", "conjecture"
        ]
    
    def _get_default_probability_markers(self) -> List[str]:
        """
        Get default probability markers.
        
        Returns:
            List of probability markers
        """
        return [
            "sometimes", "occasionally", "often", "frequently", "rarely",
            "seldom", "usually", "typically", "generally", "normally",
            "in most cases", "in some cases", "in many cases", "in rare cases",
            "in general", "as a rule", "for the most part", "about", "around",
            "approximately", "roughly", "nearly", "almost", "largely",
            "mostly", "mainly", "primarily", "predominantly", "partially"
        ]
    
    def _generate_explanation(self, uncertain_statements: List[Dict[str, Any]]) -> str:
        """
        Generate a human-readable explanation of detection results.
        
        Args:
            uncertain_statements: List of uncertain statements
            
        Returns:
            A formatted explanation string
        """
        if not uncertain_statements:
            return "No uncertain statements detected in the generated text."
        
        explanation = f"Detected {len(uncertain_statements)} statement{'s' if len(uncertain_statements) != 1 else ''} with uncertainty markers:\n"
        
        for i, s in enumerate(uncertain_statements, 1):
            explanation += f"{i}. \"{s['text']}\" - {s['reason']} "
            explanation += f"(Severity: {s['severity']}, Score: {s['uncertainty_score']:.2f})\n"
        
        return explanation.strip()
    
    def __repr__(self) -> str:
        """Return a string representation of the detector."""
        return f"UncertaintyDetector(threshold={self.threshold})" 